# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Global configuration settings applied across all NVSentinel components
global:
  # Docker image configuration
  image:
    # Image tag to use for all NVSentinel components (e.g., "main", "v1.0.0")
    tag: "main"

  # Default port for Prometheus metrics endpoint across all components
  metricsPort: 2112
  
  # Node selector for global components - used to constrain pods to nodes with specific labels
  # Example: kubernetes.io/hostname: specific-node
  nodeSelector: {}
  
  # Tolerations for global workloads - allows pods to schedule on nodes with matching taints
  # Example: - key: "nvidia.com/gpu", operator: "Exists", effect: "NoSchedule"
  tolerations: []
  
  # Affinity rules for global workloads - defines pod scheduling preferences and requirements
  # Example: podAntiAffinity to spread pods across nodes
  affinity: {}
  
  # Node selector for control plane components (platform-connectors, monitoring services)
  # Used to schedule critical infrastructure components on specific nodes
  systemNodeSelector: {}
  
  # Tolerations for system-level components
  # Allows system pods to run on tainted nodes where regular workloads cannot
  systemNodeTolerations: []

  # Enable dry-run mode across all components - operations are logged but not executed
  dryRun: false

  # Image pull secrets for accessing private container registries
  # Must be created in the namespace before deploying NVSentinel
  imagePullSecrets: []

  # Module enable/disable flags
  gpuHealthMonitor:
    enabled: true

  healthEventsAnalyzer:
    enabled: false

  faultQuarantineModule:
    enabled: false

  nodeDrainerModule:
    enabled: false

  faultRemediationModule:
    enabled: false

  janitor:
    enabled: false

  cspHealthMonitor:
    enabled: false

  syslogHealthMonitor:
    enabled: true

  labeler:
    enabled: true

  inclusterFileServer:
    enabled: false
    metricsPort: 9001
    cleanupMetricsPort: 9002

  mongodbStore:
    enabled: false

# Platform Connector configuration - central communication hub for all health monitors
platformConnector:
  image:
    repository: ghcr.io/nvidia/nvsentinel/platform-connectors
    pullPolicy: IfNotPresent
    tag: ""

  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 512Mi

  podAnnotations: {}

  # Kubernetes connector configuration
  k8sConnector:
    enabled: true
    qps: 5.0
    burst: 10

# Unix socket path for inter-component communication
socketPath: "/var/run/nvsentinel.sock"
